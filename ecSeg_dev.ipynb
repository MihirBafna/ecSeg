{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import matplotlib\n",
    "from keras import regularizers\n",
    "from scipy import ndimage\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import multi_gpu_model \n",
    "import tensorflow as tf\n",
    "from keras.metrics import binary_crossentropy\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_IM = './train_im/'\n",
    "TRAIN_MASK = './train_mask/'\n",
    "TEST_IM = './test_im/'\n",
    "TEST_MASK = './test_mask/'\n",
    "NUM_CLASSES = 4\n",
    "NUM_GPUS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(width=32, num_classes=4):\n",
    "    def conv_block(x, width, identity = False):\n",
    "        x_short = x\n",
    "        x = Conv2D(width, (3, 3), padding='same') (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(width, (3, 3), padding='same') (x)\n",
    "        x = BatchNormalization()(x)\n",
    "        if(identity):\n",
    "            x = Add()([x, x_short])\n",
    "            x = LeakyReLU()(x)\n",
    "            return x\n",
    "        x_short = Conv2D(width, (3, 3), padding='same') (x_short)\n",
    "        x_short = BatchNormalization()(x_short)\n",
    "        x = Add()([x, x_short])\n",
    "        x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    activation = 'sigmoid'\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "    c1 = conv_block(s, width, identity=True)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = conv_block(p1, width*2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = conv_block(p2, width*4)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = conv_block(p3, width*8)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = conv_block(p4, width*16)\n",
    "    c5_1 = Conv2D(width*16, (3, 3), dilation_rate = 2, padding='same') (c5)\n",
    "    c5_1 = BatchNormalization()(c5_1)\n",
    "    c5_1 = LeakyReLU()(c5_1)\n",
    "    \n",
    "    c5_2 = Conv2D(width*16, (3, 3), dilation_rate = 4, padding='same') (c5_1)\n",
    "    c5_2 = BatchNormalization()(c5_2)\n",
    "    c5_2 = LeakyReLU()(c5_2)\n",
    "    \n",
    "    c5_3 = Conv2D(width*16, (3, 3), dilation_rate = 8, padding='same') (c5_2)\n",
    "    c5_3 = BatchNormalization()(c5_3)\n",
    "    c5_3 = LeakyReLU()(c5_3)\n",
    "    c5 = Add()([c5, c5_1, c5_2, c5_3])\n",
    "\n",
    "    u6 = Conv2DTranspose(width*8, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, width*8)\n",
    "\n",
    "    u7 = Conv2DTranspose(width*4, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, width*4)\n",
    "\n",
    "    u8 = Conv2DTranspose(width*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, width*2)\n",
    "\n",
    "    u9 = Conv2DTranspose(width, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = conv_block(u9, width)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=activation) (c9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute weight for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comp_weights():\n",
    "    back_count = 0\n",
    "    ec_count = 0\n",
    "    chrom_count = 0\n",
    "    nuc_count = 0\n",
    "    alpha = 1 #used for exponential scaling\n",
    "    for x in Y_train:\n",
    "        back_count = back_count + x[:,:,0].sum()\n",
    "        nuc_count = nuc_count + x[:,:,1].sum() \n",
    "        chrom_count = chrom_count + x[:,:,2].sum()\n",
    "        ec_count = ec_count + x[:,:,3].sum()\n",
    "    print(\"number of pixels for background, nuclei, chromosomes, ecDNA: \", \n",
    "          back_count, nuc_count, chrom_count, ec_count)\n",
    "    tot = back_count + nuc_count + chrom_count + ec_count\n",
    "    back_w = 1\n",
    "    nuc_w = (nuc_count)**alpha /  (nuc_count)**alpha\n",
    "    chrom_w = (nuc_count)**alpha /(chrom_count)**alpha\n",
    "    ec_w = (nuc_count)**alpha / (ec_count)**alpha\n",
    "    weights = [back_w, nuc_w, chrom_w, ec_w]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Load training and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4760/4760 [01:02<00:00, 76.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_train():\n",
    "    num_train = len(os.listdir(TRAIN_IM))\n",
    "    X_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "    Y_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "    sys.stdout.flush()\n",
    "    #load training images\n",
    "    for count, filename in tqdm(enumerate(os.listdir(TRAIN_IM)), total=num_train):\n",
    "        img = imread(os.path.join(TRAIN_IM, filename))[:,:,2]\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
    "        X_train[count] = img\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        mask_name = name + '_mask' + ext    \n",
    "        mask = imread(os.path.join(TRAIN_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "        mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        Y_train[count] = mask\n",
    "    return X_train, Y_train\n",
    "    \n",
    "def load_test():\n",
    "    num_test = len(os.listdir(TEST_IM))\n",
    "    X_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "    Y_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "    sys.stdout.flush()\n",
    "    for count, filename in tqdm(enumerate(os.listdir(TEST_IM)), total=num_test):\n",
    "        img = imread(os.path.join(TEST_IM, filename))[:,:,2]    \n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
    "        X_test[count] = img\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        mask_name = name + '_mask' + ext    \n",
    "        mask = imread(os.path.join(TEST_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "        mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        Y_test[count] = mask\n",
    "    return X_test, Y_test\n",
    "X_train, Y_train = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight functions compiled\n"
     ]
    }
   ],
   "source": [
    "def weighted_loss(original_loss, weights_list):\n",
    "    def lossFunc(true, pred):     \n",
    "        select_class = [K.equal(tf.cast(i, tf.int64), \n",
    "                                tf.cast(K.argmax(true, axis=-1), \n",
    "                                        tf.int64)) for i in range(len(weights_list))]\n",
    "        select_class = [K.cast(x, K.floatx()) for x in select_class]\n",
    "        weights = [sel * w for sel, w in zip(select_class, weights_list)] \n",
    "        \n",
    "        scalar = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            scalar = scalar + weights[i]\n",
    "\n",
    "        loss = original_loss(true,pred)\n",
    "        loss = loss * scalar\n",
    "        return loss\n",
    "    return lossFunc\n",
    "\n",
    "# Custom loss function\n",
    "def dice_coef(y_true, y_pred):    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.))\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1-dice_coef(y_true,y_pred)\n",
    "\n",
    "def BCE_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return BCE_loss(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def mIoU(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.05, 0.1, 0.5):\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, tf.to_int32(y_pred > t), num_classes=NUM_CLASSES)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=-1)\n",
    "\n",
    "print('Weight functions compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256, 256, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 128, 128, 64) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  147584      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 512)  2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 512)  0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 128, 128, 64) 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 64) 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 128, 128, 64) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 8224        leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256, 256, 32) 128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 256, 256, 32) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 32) 9248        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256, 256, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256, 256, 32) 0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 256, 256, 32) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 4)  132         leaky_re_lu_21[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 17,997,604\n",
      "Trainable params: 17,985,764\n",
      "Non-trainable params: 11,840\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pixels for background, nuclei, chromosomes, ecDNA:  264513088 39182693 11870701 541457\n",
      "WARNING:tensorflow:From <ipython-input-6-caf9fe44172a>:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1178: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_classes=NUM_CLASSES)\n",
    "print(model.summary())\n",
    "if(NUM_GPUS > 1):\n",
    "    model = multi_gpu_model(model, gpus=8)\n",
    "weights = comp_weights()\n",
    "model.compile(optimizer='Adam', loss = weighted_loss(bce_dice, weights), metrics = [mIoU])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3808 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "3808/3808 [==============================] - 72s 19ms/step - loss: 0.9425 - mIoU: 0.1388 - val_loss: 0.9953 - val_mIoU: 0.1465\n",
      "Epoch 2/50\n",
      "3808/3808 [==============================] - 29s 8ms/step - loss: 0.5500 - mIoU: 0.1474 - val_loss: 0.4295 - val_mIoU: 0.1486\n",
      "Epoch 3/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.3767 - mIoU: 0.1518 - val_loss: 0.3169 - val_mIoU: 0.1583\n",
      "Epoch 4/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.2919 - mIoU: 0.1774 - val_loss: 0.2401 - val_mIoU: 0.2111\n",
      "Epoch 5/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.2251 - mIoU: 0.2493 - val_loss: 0.1722 - val_mIoU: 0.2892\n",
      "Epoch 6/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1892 - mIoU: 0.3250 - val_loss: 0.1430 - val_mIoU: 0.3589\n",
      "Epoch 7/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1615 - mIoU: 0.3883 - val_loss: 0.1332 - val_mIoU: 0.4158\n",
      "Epoch 8/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1586 - mIoU: 0.4397 - val_loss: 0.1443 - val_mIoU: 0.4618\n",
      "Epoch 9/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1400 - mIoU: 0.4811 - val_loss: 0.1318 - val_mIoU: 0.4994\n",
      "Epoch 10/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1265 - mIoU: 0.5157 - val_loss: 0.1013 - val_mIoU: 0.5314\n",
      "Epoch 11/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1158 - mIoU: 0.5455 - val_loss: 0.1013 - val_mIoU: 0.5590\n",
      "Epoch 12/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1182 - mIoU: 0.5711 - val_loss: 0.0937 - val_mIoU: 0.5827\n",
      "Epoch 13/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1077 - mIoU: 0.5933 - val_loss: 0.0963 - val_mIoU: 0.6035\n",
      "Epoch 14/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1120 - mIoU: 0.6129 - val_loss: 0.0970 - val_mIoU: 0.6219\n",
      "Epoch 15/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1058 - mIoU: 0.6303 - val_loss: 0.0895 - val_mIoU: 0.6384\n",
      "Epoch 16/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1007 - mIoU: 0.6459 - val_loss: 0.0844 - val_mIoU: 0.6532\n",
      "Epoch 17/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0961 - mIoU: 0.6601 - val_loss: 0.0833 - val_mIoU: 0.6667\n",
      "Epoch 18/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0957 - mIoU: 0.6729 - val_loss: 0.0880 - val_mIoU: 0.6789\n",
      "Epoch 19/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0963 - mIoU: 0.6846 - val_loss: 0.0775 - val_mIoU: 0.6902\n",
      "Epoch 20/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0963 - mIoU: 0.6954 - val_loss: 0.0821 - val_mIoU: 0.7004\n",
      "Epoch 21/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0941 - mIoU: 0.7052 - val_loss: 0.0829 - val_mIoU: 0.7099\n",
      "Epoch 22/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.1060 - mIoU: 0.7143 - val_loss: 0.1143 - val_mIoU: 0.7185\n",
      "Epoch 23/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0999 - mIoU: 0.7225 - val_loss: 0.0981 - val_mIoU: 0.7264\n",
      "Epoch 24/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0978 - mIoU: 0.7302 - val_loss: 0.1026 - val_mIoU: 0.7339\n",
      "Epoch 25/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0867 - mIoU: 0.7375 - val_loss: 0.0799 - val_mIoU: 0.7410\n",
      "Epoch 26/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0845 - mIoU: 0.7444 - val_loss: 0.0873 - val_mIoU: 0.7477\n",
      "Epoch 27/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0862 - mIoU: 0.7508 - val_loss: 0.0757 - val_mIoU: 0.7539\n",
      "Epoch 28/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0833 - mIoU: 0.7569 - val_loss: 0.0759 - val_mIoU: 0.7598\n",
      "Epoch 29/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0804 - mIoU: 0.7627 - val_loss: 0.0793 - val_mIoU: 0.7654\n",
      "Epoch 30/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0915 - mIoU: 0.7680 - val_loss: 0.0836 - val_mIoU: 0.7706\n",
      "Epoch 31/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0871 - mIoU: 0.7731 - val_loss: 0.0796 - val_mIoU: 0.7755\n",
      "Epoch 32/50\n",
      "3808/3808 [==============================] - 27s 7ms/step - loss: 0.0862 - mIoU: 0.7779 - val_loss: 0.0739 - val_mIoU: 0.7802\n",
      "Epoch 33/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0826 - mIoU: 0.7824 - val_loss: 0.0778 - val_mIoU: 0.7846\n",
      "Epoch 34/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0801 - mIoU: 0.7868 - val_loss: 0.0786 - val_mIoU: 0.7889\n",
      "Epoch 35/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0795 - mIoU: 0.7909 - val_loss: 0.0743 - val_mIoU: 0.7929\n",
      "Epoch 36/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0817 - mIoU: 0.7948 - val_loss: 0.0831 - val_mIoU: 0.7967\n",
      "Epoch 37/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0768 - mIoU: 0.7986 - val_loss: 0.0733 - val_mIoU: 0.8004\n",
      "Epoch 38/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0750 - mIoU: 0.8022 - val_loss: 0.0770 - val_mIoU: 0.8040\n",
      "Epoch 39/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0756 - mIoU: 0.8057 - val_loss: 0.0812 - val_mIoU: 0.8073\n",
      "Epoch 40/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0755 - mIoU: 0.8089 - val_loss: 0.0761 - val_mIoU: 0.8105\n",
      "Epoch 41/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0766 - mIoU: 0.8121 - val_loss: 0.0829 - val_mIoU: 0.8136\n",
      "Epoch 42/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0784 - mIoU: 0.8151 - val_loss: 0.0733 - val_mIoU: 0.8165\n",
      "Epoch 43/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0753 - mIoU: 0.8180 - val_loss: 0.0734 - val_mIoU: 0.8194\n",
      "Epoch 44/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0720 - mIoU: 0.8208 - val_loss: 0.0685 - val_mIoU: 0.8221\n",
      "Epoch 45/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0718 - mIoU: 0.8235 - val_loss: 0.0825 - val_mIoU: 0.8248\n",
      "Epoch 46/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0709 - mIoU: 0.8261 - val_loss: 0.0782 - val_mIoU: 0.8273\n",
      "Epoch 47/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0705 - mIoU: 0.8286 - val_loss: 0.0729 - val_mIoU: 0.8298\n",
      "Epoch 48/50\n",
      "3808/3808 [==============================] - 28s 7ms/step - loss: 0.0684 - mIoU: 0.8310 - val_loss: 0.0724 - val_mIoU: 0.8322\n",
      "Epoch 49/50\n",
      " 896/3808 [======>.......................] - ETA: 17s - loss: 0.0644 - mIoU: 0.8326"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "history = model.fit(X_train, Y_train, validation_split=0.20, batch_size = 128, \n",
    "                             verbose=1, epochs=50, callbacks=[earlystopper])\n",
    "model_out = model.layers[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['mIoU'])\n",
    "plt.plot(history.history['val_mIoU'])\n",
    "plt.title('ecDNA IoU score')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('IoU.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.title('ecDNA loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_out.save('ecDNA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ecDNA_model.h5')\n",
    "model.save('ecDNA_ResUnet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
