{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import matplotlib\n",
    "from keras import regularizers\n",
    "from scipy import ndimage\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import multi_gpu_model \n",
    "import tensorflow as tf\n",
    "from keras.metrics import binary_crossentropy\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_IM = './train_im/'\n",
    "TRAIN_MASK = './train_mask/'\n",
    "TEST_IM = './test_im/'\n",
    "TEST_MASK = './test_mask/'\n",
    "NUM_CLASSES = 4\n",
    "NUM_GPUS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Load training and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    num_train = len(os.listdir(TRAIN_IM))\n",
    "    X_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "    Y_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "    sys.stdout.flush()\n",
    "    #load training images\n",
    "    for count, filename in tqdm(enumerate(os.listdir(TRAIN_IM)), total=num_train):\n",
    "        img = imread(os.path.join(TRAIN_IM, filename))[:,:,2]\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
    "        X_train[count] = img\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        mask_name = name + '_mask' + ext    \n",
    "        mask = imread(os.path.join(TRAIN_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "        mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        Y_train[count] = mask\n",
    "    return X_train, Y_train\n",
    "    \n",
    "def load_test():\n",
    "    num_test = len(os.listdir(TEST_IM))\n",
    "    X_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "    Y_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "    sys.stdout.flush()\n",
    "    for count, filename in tqdm(enumerate(os.listdir(TEST_IM)), total=num_test):\n",
    "        img = imread(os.path.join(TEST_IM, filename))[:,:,2]    \n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
    "        X_test[count] = img\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        mask_name = name + '_mask' + ext    \n",
    "        mask = imread(os.path.join(TEST_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "        mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        Y_test[count] = mask\n",
    "    return X_test, Y_test\n",
    "X_train, Y_train = load_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute weight for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comp_weights():\n",
    "    back_count = 0\n",
    "    ec_count = 0\n",
    "    chrom_count = 0\n",
    "    nuc_count = 0\n",
    "    alpha = 1 #used for exponential scaling\n",
    "    for x in Y_train:\n",
    "        back_count = back_count + x[:,:,0].sum()\n",
    "        nuc_count = nuc_count + x[:,:,1].sum() \n",
    "        chrom_count = chrom_count + x[:,:,2].sum()\n",
    "        ec_count = ec_count + x[:,:,3].sum()\n",
    "    print(\"number of pixels for background, nuclei, chromosomes, ecDNA: \", \n",
    "          back_count, nuc_count, chrom_count, ec_count)\n",
    "    tot = back_count + nuc_count + chrom_count + ec_count\n",
    "    back_w = 1\n",
    "    nuc_w = (nuc_count)**alpha /  (nuc_count)**alpha\n",
    "    chrom_w = (nuc_count)**alpha /(chrom_count)**alpha\n",
    "    ec_w = (nuc_count)**alpha / (ec_count)**alpha\n",
    "    weights = [back_w, nuc_w, chrom_w, ec_w]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def weighted_loss(original_loss, weights_list):\n",
    "    def lossFunc(true, pred):     \n",
    "        select_class = [K.equal(tf.cast(i, tf.int64), \n",
    "                                tf.cast(K.argmax(true, axis=-1), \n",
    "                                        tf.int64)) for i in range(len(weights_list))]\n",
    "        select_class = [K.cast(x, K.floatx()) for x in select_class]\n",
    "        weights = [sel * w for sel, w in zip(select_class, weights_list)] \n",
    "        \n",
    "        scalar = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            scalar = scalar + weights[i]\n",
    "\n",
    "        loss = original_loss(true,pred)\n",
    "        loss = loss * scalar\n",
    "        return loss\n",
    "    return lossFunc\n",
    "\n",
    "# Custom loss function\n",
    "def dice_coef(y_true, y_pred):    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.))\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1-dice_coef(y_true,y_pred)\n",
    "\n",
    "def BCE_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return BCE_loss(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def mIoU(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.05, 0.1, 0.5):\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, tf.to_int32(y_pred > t), num_classes=NUM_CLASSES)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=-1)\n",
    "\n",
    "print('Weight functions compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(width=32, num_classes=4):\n",
    "    def conv_block(x, width, k_reg=False):\n",
    "        c1 = Conv2D(width, (3, 3), activation='elu', padding='same') (x)\n",
    "        if(k_reg):\n",
    "            c1 = Conv2D(width, (3, 3), activation='elu', padding='same', kernel_regularizer=regularizers.l2(0.001)) (c1)\n",
    "        else:\n",
    "            c1 = Conv2D(width, (3, 3), activation='elu', padding='same') (c1)\n",
    "        return c1\n",
    "\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    activation = 'sigmoid'\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "    c1 = conv_block(s, width)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = conv_block(p1, width*2, k_reg=True)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = conv_block(p2, width*4, k_reg=True)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = conv_block(p3, width*8, k_reg=True)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = conv_block(p4, width*16)\n",
    "\n",
    "    u6 = Conv2DTranspose(width*8, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, width*8)\n",
    "\n",
    "    u7 = Conv2DTranspose(width*4, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, width*4)\n",
    "\n",
    "    u8 = Conv2DTranspose(width*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, width*2)\n",
    "\n",
    "    u9 = Conv2DTranspose(width, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = conv_block(u9, width)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=activation) (c9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build and compile model (multi-GPU support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=NUM_CLASSES)\n",
    "if(NUM_GPUS > 1):\n",
    "    model = multi_gpu_model(model, gpus=NUM_GPUS)\n",
    "weights = comp_weights()\n",
    "model.compile(optimizer='Adamax', loss = weighted_loss(bce_dice, weights), metrics = [mIoU])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=7, verbose=1)\n",
    "history = model.fit(X_train, Y_train, validation_split=0.25, batch_size = 16, \n",
    "                             verbose=1, epochs=45, callbacks=[earlystopper])\n",
    "model_out = model.layers[-2]\n",
    "model_out.save_weights(filepath=\"./ecDNA_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['mIoU'])\n",
    "plt.plot(history.history['val_mIoU'])\n",
    "plt.title('ecDNA IoU score')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('IoU.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.title('ecDNA loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save as also model rather than just as a weight file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.load_weights(\"./ecDNA_model.hdf5\")\n",
    "model.save('ecDNA_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "X_test, Y_test = load_test()\n",
    "onlyfiles = [f for f in listdir(TEST_IM) if isfile(join(TEST_IM, f))]\n",
    "for i in X_test:\n",
    "    x = np.expand_dims(i, axis=0)\n",
    "    comb_pred = np.squeeze(model.predict(x, verbose=0))\n",
    "    plt.imshow(comb_pred[...,3])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras; print(keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
