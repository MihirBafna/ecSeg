{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import matplotlib\n",
    "from scipy import ndimage\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils import multi_gpu_model \n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_IM = './train_im/'\n",
    "TRAIN_MASK = './train_mask/'\n",
    "TEST_IM = './test_im/'\n",
    "TEST_MASK = './test_mask/'\n",
    "NUM_CLASSES = 4\n",
    "NUM_GPUS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Load training and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = len(os.listdir(TRAIN_IM))\n",
    "X_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((num_train, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "sys.stdout.flush()\n",
    "#load training images\n",
    "for count, filename in tqdm(enumerate(os.listdir(TRAIN_IM)), total=num_train):\n",
    "    img = imread(os.path.join(TRAIN_IM, filename))[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[count] = img\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    mask_name = name + '_mask' + ext    \n",
    "    mask = imread(os.path.join(TRAIN_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    Y_train[count] = mask\n",
    "    \n",
    "#load test images\n",
    "num_test = len(os.listdir(TEST_IM))\n",
    "X_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((num_test, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.bool)\n",
    "sys.stdout.flush()\n",
    "for count, filename in tqdm(enumerate(os.listdir(TEST_IM)), total=num_test):\n",
    "    img = imread(os.path.join(TEST_IM, filename))[:,:,:IMG_CHANNELS]    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[count] = img\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    mask_name = name + '_mask' + ext    \n",
    "    mask = imread(os.path.join(TEST_MASK, mask_name))[:,:,:NUM_CLASSES]\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    Y_test[count] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute weight for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "back_count = 0\n",
    "ec_count = 0\n",
    "chrom_count = 0\n",
    "nuc_count = 0\n",
    "alpha = 1 #used for exponential scaling\n",
    "for x in Y_train:\n",
    "    back_count = back_count + x[:,:,0].sum()\n",
    "    nuc_count = nuc_count + x[:,:,1].sum() \n",
    "    chrom_count = chrom_count + x[:,:,2].sum()\n",
    "    ec_count = ec_count + x[:,:,3].sum()\n",
    "print(\"number of pixels for background, nuclei, chromosomes, ecDNA: \", \n",
    "      back_count, nuc_count, chrom_count, ec_count)\n",
    "tot = back_count + nuc_count + chrom_count + ec_count\n",
    "back_w = 1\n",
    "nuc_w = (nuc_count)**alpha /  (nuc_count)**alpha\n",
    "chrom_w = (nuc_count)**alpha /(chrom_count)**alpha\n",
    "ec_w = (nuc_count)**alpha / (ec_count)**alpha\n",
    "weights = [back_w, nuc_w, chrom_w, ec_w]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss function and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Custom IoU metric\n",
    "from keras.metrics import binary_crossentropy\n",
    "\n",
    "def mIoU(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.05, 0.1, 0.5):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, num_classes=NUM_CLASSES)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=-1)\n",
    "\n",
    "def weighted_loss(original_loss, weights_list):\n",
    "    def lossFunc(true, pred):     \n",
    "        select_class = [K.equal(tf.cast(i, tf.int64), \n",
    "                                tf.cast(K.argmax(true, axis=-1), \n",
    "                                        tf.int64)) for i in range(len(weights_list))]\n",
    "        select_class = [K.cast(x, K.floatx()) for x in select_class]\n",
    "        weights = [sel * w for sel, w in zip(select_class, weights_list)] \n",
    "        \n",
    "        scalar = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            scalar = scalar + weights[i]\n",
    "\n",
    "        loss = original_loss(true,pred)\n",
    "        loss = loss * scalar\n",
    "        return loss\n",
    "    return lossFunc\n",
    "\n",
    "smooth = 1.\n",
    "# Custom loss function\n",
    "def dice_coef(y_true, y_pred):    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1-dice_coef(y_true,y_pred)\n",
    "\n",
    "def BCE_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return BCE_loss(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "print('Weight functions compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(width=32, NUM_CLASSES=4):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    activation = 'sigmoid'\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "    c1 = Conv2D(width, (3, 3), activation='elu', padding='same') (s)\n",
    "    c1 = Conv2D(width, (3, 3), activation='elu', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(width*2, (3, 3), activation='elu', padding='same') (p1)\n",
    "    c2 = Conv2D(width*2, (3, 3), activation='elu', padding='same', \n",
    "                kernel_regularizer=regularizers.l2(0.001)) (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(width*4, (3, 3), activation='elu', padding='same') (p2)\n",
    "    c3 = Conv2D(width*4, (3, 3), activation='elu', padding='same', \n",
    "                kernel_regularizer=regularizers.l2(0.001)) (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(width*8, (3, 3), activation='elu', padding='same') (p3)\n",
    "    c4 = Conv2D(width*8, (3, 3), activation='elu', padding='same', \n",
    "                kernel_regularizer=regularizers.l2(0.001)) (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(width*16, (3, 3), activation='elu', padding='same') (p4)\n",
    "    c5 = Conv2D(width*16, (3, 3), activation='elu', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(width*8, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(width*8, (3, 3), activation='elu', padding='same') (u6)\n",
    "    c6 = Conv2D(width*8, (3, 3), activation='elu', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(width*4, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(width*4, (3, 3), activation='elu', padding='same') (u7)\n",
    "    c7 = Conv2D(width*4, (3, 3), activation='elu', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(width*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(width*2, (3, 3), activation='elu', padding='same') (u8)\n",
    "    c8 = Conv2D(width*2, (3, 3), activation='elu', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(width, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(width, (3, 3), activation='elu', padding='same') (u9)\n",
    "    c9 = Conv2D(width, (3, 3), activation='elu', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(NUM_CLASSES, (1, 1), activation=activation) (c9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build and compile model (multi-GPU support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "if(NUM_GPUS > 1):\n",
    "    model = multi_gpu_model(model, gpus=NUM_GPUS)\n",
    "model.compile(optimizer='Adamax', loss = weighted_loss(bce_dice, weights), metrics = [mIoU])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=7, verbose=1)\n",
    "history = parallel_model.fit(X_train, Y_train, validation_split=0.25, batch_size = 16, \n",
    "                             verbose=1, epochs=45, callbacks=[earlystopper])\n",
    "model_out = parallel_model.layers[-2]\n",
    "model_out.save_weights(filepath=\"./ecDNA_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['mIoU'])\n",
    "plt.plot(history.history['val_mIoU'])\n",
    "plt.title('ecDNA IoU score')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('IoU.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.title('ecDNA loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save as also model rather than just as a weight file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.load_weights(\"./ecDNA_model.hdf5\")\n",
    "model.save('ecDNA_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "onlyfiles = [f for f in listdir(TEST_IM) if isfile(join(TEST_IM, f))]\n",
    "for i in onlyfiles:\n",
    "    img = TEST_IM + i\n",
    "    img = imread(img)\n",
    "    name = './results/' +i\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    comb_pred = np.squeeze(model.predict(x, verbose=0))\n",
    "    np.save(name, comb_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
